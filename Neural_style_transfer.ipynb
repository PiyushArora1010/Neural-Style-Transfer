{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Neural_style_transfer.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 262,
      "metadata": {
        "id": "n-unMUJmHE6Y"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow.keras.applications import VGG19\n",
        "from tensorflow.keras import Model\n",
        "import cv2 as cv"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vgg19 = VGG19(include_top=False, weights='imagenet')\n",
        "for layer in vgg19.layers:\n",
        "  print(layer.name, layer.output_shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nNiKaDeUHUem",
        "outputId": "db80d3e8-ec49-4704-fd02-3ea57d51b051"
      },
      "execution_count": 263,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_17 [(None, None, None, 3)]\n",
            "block1_conv1 (None, None, None, 64)\n",
            "block1_conv2 (None, None, None, 64)\n",
            "block1_pool (None, None, None, 64)\n",
            "block2_conv1 (None, None, None, 128)\n",
            "block2_conv2 (None, None, None, 128)\n",
            "block2_pool (None, None, None, 128)\n",
            "block3_conv1 (None, None, None, 256)\n",
            "block3_conv2 (None, None, None, 256)\n",
            "block3_conv3 (None, None, None, 256)\n",
            "block3_conv4 (None, None, None, 256)\n",
            "block3_pool (None, None, None, 256)\n",
            "block4_conv1 (None, None, None, 512)\n",
            "block4_conv2 (None, None, None, 512)\n",
            "block4_conv3 (None, None, None, 512)\n",
            "block4_conv4 (None, None, None, 512)\n",
            "block4_pool (None, None, None, 512)\n",
            "block5_conv1 (None, None, None, 512)\n",
            "block5_conv2 (None, None, None, 512)\n",
            "block5_conv3 (None, None, None, 512)\n",
            "block5_conv4 (None, None, None, 512)\n",
            "block5_pool (None, None, None, 512)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "content_layers = ['block4_conv2']\n",
        "style_layers = ['block'+str(i)+'_conv1' for i in range(1,6)]"
      ],
      "metadata": {
        "id": "dRT7RQleHUbY"
      },
      "execution_count": 264,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gram_matrix(input_tensor):\n",
        "  result = tf.linalg.einsum('bijc,bijd->bcd', input_tensor, input_tensor)\n",
        "  gram_matrix = tf.expand_dims(result, axis=0)\n",
        "  input_shape = tf.shape(input_tensor)\n",
        "  ij = tf.cast(input_shape[1]*input_shape[2], tf.float32)\n",
        "  return gram_matrix/ij "
      ],
      "metadata": {
        "id": "GiMqbCofHUY7"
      },
      "execution_count": 265,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_vgg19():\n",
        "  global vgg19,content_layers,style_layers\n",
        "  vgg19.trainable = False\n",
        "  content_output = vgg19.get_layer(style_layers[0]).output\n",
        "  style_output = [vgg19.get_layer(layer).output for layer in style_layers]\n",
        "  gram_style_output = [gram_matrix(output) for output in style_output]\n",
        "  model = Model([vgg19.input],[content_output, gram_style_output])\n",
        "  return model"
      ],
      "metadata": {
        "id": "Xv3QYse8HUWy"
      },
      "execution_count": 266,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "opt = tf.optimizers.Adam(learning_rate=0.01, beta_1 = 0.99, epsilon = 1e-1) "
      ],
      "metadata": {
        "id": "z8KXRalwHUUO"
      },
      "execution_count": 267,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_object(style_outputs, content_outputs, style_target, content_target):\n",
        "  sweight = 1e-2\n",
        "  cweight = 1e-1\n",
        "  content_loss = tf.reduce_mean((content_outputs - content_target)**2)/2\n",
        "  style_loss = tf.add_n([tf.reduce_mean((style_outputs[i]-style_target[i])**2) for i in range(len(style_outputs))])/2\n",
        "  total_loss = sweight*style_loss + cweight*content_loss\n",
        "  return total_loss"
      ],
      "metadata": {
        "id": "j_lDpLEDHUR3"
      },
      "execution_count": 268,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "content_image = cv.imread('/content/image.jpeg')\n",
        "style_image = cv.imread('/content/style.jpg')\n",
        "content_image = cv.resize(content_image, (1024,1024))\n",
        "style_image = cv.resize(style_image, (1024,1024))\n",
        "content_image = np.array(content_image, np.float32)/255\n",
        "style_image = np.array(style_image, np.float32)/255"
      ],
      "metadata": {
        "id": "hK_lCoTAZdJw"
      },
      "execution_count": 269,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vgg = load_vgg19()\n",
        "content_target = vgg(np.array([content_image*255]))[0]\n",
        "style_target = vgg(np.array([style_image*255]))[1]"
      ],
      "metadata": {
        "id": "8dcYSrofWoO0"
      },
      "execution_count": 270,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_step(image, epoch):\n",
        "  with tf.GradientTape() as tape:\n",
        "    output = vgg(image*255)\n",
        "    loss = loss_object(output[1], output[0], style_target, content_target)\n",
        "  gradient = tape.gradient(loss, image)\n",
        "  opt.apply_gradients([(gradient, image)])\n",
        "  image.assign(tf.clip_by_value(image, clip_value_min=0.0, clip_value_max=1.0))\n",
        "  tf.print(f\"Loss = {loss}\")"
      ],
      "metadata": {
        "id": "zOuPNICuHUPU"
      },
      "execution_count": 271,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 300\n",
        "image = tf.image.convert_image_dtype(content_image, tf.float32)\n",
        "image = tf.Variable([image])\n",
        "for i in range(EPOCHS):\n",
        "  train_step(image, i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XG_Aer2DHUMw",
        "outputId": "42af7e69-1d70-40fa-fe59-ac5c8fc543be"
      },
      "execution_count": 272,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss = 859114944.0\n",
            "Loss = 641099200.0\n",
            "Loss = 493174880.0\n",
            "Loss = 391342976.0\n",
            "Loss = 320678592.0\n",
            "Loss = 272140352.0\n",
            "Loss = 238797680.0\n",
            "Loss = 216676288.0\n",
            "Loss = 200725248.0\n",
            "Loss = 188602032.0\n",
            "Loss = 179855344.0\n",
            "Loss = 173242048.0\n",
            "Loss = 167671280.0\n",
            "Loss = 162741008.0\n",
            "Loss = 158213904.0\n",
            "Loss = 153940224.0\n",
            "Loss = 149828768.0\n",
            "Loss = 145831600.0\n",
            "Loss = 141828016.0\n",
            "Loss = 137657920.0\n",
            "Loss = 133261992.0\n",
            "Loss = 128670248.0\n",
            "Loss = 123984200.0\n",
            "Loss = 119299344.0\n",
            "Loss = 114726256.0\n",
            "Loss = 110359632.0\n",
            "Loss = 106249872.0\n",
            "Loss = 102410120.0\n",
            "Loss = 98847840.0\n",
            "Loss = 95538136.0\n",
            "Loss = 92450520.0\n",
            "Loss = 89558144.0\n",
            "Loss = 86846704.0\n",
            "Loss = 84273176.0\n",
            "Loss = 81838448.0\n",
            "Loss = 79535128.0\n",
            "Loss = 77372728.0\n",
            "Loss = 75355408.0\n",
            "Loss = 73481344.0\n",
            "Loss = 71749136.0\n",
            "Loss = 70139032.0\n",
            "Loss = 68624800.0\n",
            "Loss = 67191536.0\n",
            "Loss = 65825388.0\n",
            "Loss = 64511576.0\n",
            "Loss = 63248252.0\n",
            "Loss = 62034836.0\n",
            "Loss = 60874276.0\n",
            "Loss = 59756168.0\n",
            "Loss = 58681692.0\n",
            "Loss = 57648764.0\n",
            "Loss = 56658828.0\n",
            "Loss = 55706900.0\n",
            "Loss = 54782864.0\n",
            "Loss = 53885432.0\n",
            "Loss = 53012104.0\n",
            "Loss = 52159408.0\n",
            "Loss = 51324724.0\n",
            "Loss = 50506564.0\n",
            "Loss = 49705436.0\n",
            "Loss = 48925676.0\n",
            "Loss = 48162340.0\n",
            "Loss = 47415440.0\n",
            "Loss = 46684668.0\n",
            "Loss = 45967100.0\n",
            "Loss = 45261996.0\n",
            "Loss = 44567624.0\n",
            "Loss = 43886808.0\n",
            "Loss = 43219456.0\n",
            "Loss = 42566572.0\n",
            "Loss = 41929076.0\n",
            "Loss = 41302372.0\n",
            "Loss = 40683964.0\n",
            "Loss = 40077072.0\n",
            "Loss = 39484680.0\n",
            "Loss = 38905780.0\n",
            "Loss = 38338708.0\n",
            "Loss = 37782752.0\n",
            "Loss = 37238392.0\n",
            "Loss = 36703300.0\n",
            "Loss = 36174436.0\n",
            "Loss = 35653328.0\n",
            "Loss = 35140480.0\n",
            "Loss = 34635732.0\n",
            "Loss = 34137348.0\n",
            "Loss = 33646760.0\n",
            "Loss = 33164770.0\n",
            "Loss = 32689500.0\n",
            "Loss = 32220974.0\n",
            "Loss = 31758196.0\n",
            "Loss = 31301614.0\n",
            "Loss = 30851150.0\n",
            "Loss = 30407964.0\n",
            "Loss = 29972110.0\n",
            "Loss = 29542006.0\n",
            "Loss = 29119400.0\n",
            "Loss = 28703872.0\n",
            "Loss = 28297396.0\n",
            "Loss = 27898758.0\n",
            "Loss = 27507748.0\n",
            "Loss = 27123828.0\n",
            "Loss = 26745938.0\n",
            "Loss = 26374040.0\n",
            "Loss = 26007026.0\n",
            "Loss = 25645300.0\n",
            "Loss = 25290368.0\n",
            "Loss = 24941024.0\n",
            "Loss = 24597538.0\n",
            "Loss = 24261522.0\n",
            "Loss = 23933014.0\n",
            "Loss = 23610506.0\n",
            "Loss = 23294088.0\n",
            "Loss = 22983360.0\n",
            "Loss = 22676394.0\n",
            "Loss = 22371508.0\n",
            "Loss = 22069746.0\n",
            "Loss = 21771558.0\n",
            "Loss = 21479232.0\n",
            "Loss = 21192488.0\n",
            "Loss = 20911544.0\n",
            "Loss = 20635256.0\n",
            "Loss = 20364316.0\n",
            "Loss = 20098970.0\n",
            "Loss = 19839054.0\n",
            "Loss = 19583758.0\n",
            "Loss = 19332426.0\n",
            "Loss = 19084290.0\n",
            "Loss = 18837546.0\n",
            "Loss = 18593776.0\n",
            "Loss = 18352838.0\n",
            "Loss = 18113944.0\n",
            "Loss = 17878580.0\n",
            "Loss = 17647816.0\n",
            "Loss = 17422490.0\n",
            "Loss = 17201752.0\n",
            "Loss = 16986288.0\n",
            "Loss = 16775086.0\n",
            "Loss = 16567120.0\n",
            "Loss = 16362688.0\n",
            "Loss = 16160323.0\n",
            "Loss = 15960146.0\n",
            "Loss = 15761942.0\n",
            "Loss = 15566565.0\n",
            "Loss = 15373923.0\n",
            "Loss = 15184474.0\n",
            "Loss = 14997960.0\n",
            "Loss = 14814248.0\n",
            "Loss = 14633498.0\n",
            "Loss = 14455990.0\n",
            "Loss = 14281316.0\n",
            "Loss = 14108838.0\n",
            "Loss = 13938540.0\n",
            "Loss = 13769888.0\n",
            "Loss = 13603500.0\n",
            "Loss = 13439501.0\n",
            "Loss = 13277504.0\n",
            "Loss = 13117310.0\n",
            "Loss = 12958849.0\n",
            "Loss = 12802551.0\n",
            "Loss = 12648880.0\n",
            "Loss = 12497641.0\n",
            "Loss = 12348343.0\n",
            "Loss = 12201389.0\n",
            "Loss = 12056872.0\n",
            "Loss = 11914806.0\n",
            "Loss = 11774949.0\n",
            "Loss = 11637281.0\n",
            "Loss = 11501825.0\n",
            "Loss = 11368608.0\n",
            "Loss = 11237438.0\n",
            "Loss = 11107996.0\n",
            "Loss = 10980691.0\n",
            "Loss = 10855657.0\n",
            "Loss = 10732498.0\n",
            "Loss = 10611391.0\n",
            "Loss = 10492215.0\n",
            "Loss = 10374913.0\n",
            "Loss = 10259557.0\n",
            "Loss = 10146042.0\n",
            "Loss = 10034157.0\n",
            "Loss = 9924256.0\n",
            "Loss = 9815872.0\n",
            "Loss = 9708994.0\n",
            "Loss = 9603278.0\n",
            "Loss = 9498575.0\n",
            "Loss = 9395343.0\n",
            "Loss = 9293270.0\n",
            "Loss = 9192559.0\n",
            "Loss = 9093382.0\n",
            "Loss = 8995695.0\n",
            "Loss = 8899403.0\n",
            "Loss = 8804326.0\n",
            "Loss = 8710447.0\n",
            "Loss = 8617821.0\n",
            "Loss = 8526655.0\n",
            "Loss = 8436737.0\n",
            "Loss = 8348047.5\n",
            "Loss = 8260579.0\n",
            "Loss = 8174002.0\n",
            "Loss = 8088432.0\n",
            "Loss = 8003776.5\n",
            "Loss = 7920206.0\n",
            "Loss = 7837687.5\n",
            "Loss = 7756276.0\n",
            "Loss = 7676256.0\n",
            "Loss = 7597574.0\n",
            "Loss = 7520058.0\n",
            "Loss = 7443607.5\n",
            "Loss = 7368222.0\n",
            "Loss = 7293849.5\n",
            "Loss = 7220206.5\n",
            "Loss = 7147385.0\n",
            "Loss = 7075391.0\n",
            "Loss = 7004181.5\n",
            "Loss = 6933809.0\n",
            "Loss = 6864515.0\n",
            "Loss = 6796394.0\n",
            "Loss = 6729374.0\n",
            "Loss = 6663269.0\n",
            "Loss = 6598027.5\n",
            "Loss = 6533560.0\n",
            "Loss = 6469948.5\n",
            "Loss = 6407017.0\n",
            "Loss = 6344720.5\n",
            "Loss = 6283045.0\n",
            "Loss = 6222167.0\n",
            "Loss = 6162051.0\n",
            "Loss = 6102798.0\n",
            "Loss = 6044457.0\n",
            "Loss = 5986996.5\n",
            "Loss = 5930484.5\n",
            "Loss = 5874775.0\n",
            "Loss = 5819766.5\n",
            "Loss = 5765500.5\n",
            "Loss = 5711941.0\n",
            "Loss = 5658992.0\n",
            "Loss = 5606573.0\n",
            "Loss = 5554785.0\n",
            "Loss = 5503832.5\n",
            "Loss = 5453713.5\n",
            "Loss = 5404327.5\n",
            "Loss = 5355661.5\n",
            "Loss = 5307814.0\n",
            "Loss = 5260734.0\n",
            "Loss = 5214347.5\n",
            "Loss = 5168619.5\n",
            "Loss = 5123480.0\n",
            "Loss = 5078880.0\n",
            "Loss = 5034728.0\n",
            "Loss = 4990873.5\n",
            "Loss = 4947405.5\n",
            "Loss = 4904465.5\n",
            "Loss = 4862086.0\n",
            "Loss = 4820317.0\n",
            "Loss = 4779219.5\n",
            "Loss = 4738677.0\n",
            "Loss = 4698709.5\n",
            "Loss = 4659279.5\n",
            "Loss = 4620359.5\n",
            "Loss = 4581943.5\n",
            "Loss = 4543948.0\n",
            "Loss = 4506279.5\n",
            "Loss = 4468969.5\n",
            "Loss = 4432093.0\n",
            "Loss = 4395629.5\n",
            "Loss = 4359588.0\n",
            "Loss = 4323986.0\n",
            "Loss = 4288795.0\n",
            "Loss = 4254037.5\n",
            "Loss = 4219751.5\n",
            "Loss = 4185927.25\n",
            "Loss = 4152499.75\n",
            "Loss = 4119530.25\n",
            "Loss = 4086949.5\n",
            "Loss = 4054723.25\n",
            "Loss = 4022871.0\n",
            "Loss = 3991404.75\n",
            "Loss = 3960272.0\n",
            "Loss = 3929467.0\n",
            "Loss = 3899012.75\n",
            "Loss = 3868933.75\n",
            "Loss = 3839204.5\n",
            "Loss = 3809842.25\n",
            "Loss = 3780884.75\n",
            "Loss = 3752294.25\n",
            "Loss = 3724059.5\n",
            "Loss = 3696155.75\n",
            "Loss = 3668547.5\n",
            "Loss = 3641219.0\n",
            "Loss = 3614155.0\n",
            "Loss = 3587351.75\n",
            "Loss = 3560840.75\n",
            "Loss = 3534643.25\n",
            "Loss = 3508774.5\n",
            "Loss = 3483264.75\n",
            "Loss = 3458102.5\n",
            "Loss = 3433240.75\n",
            "Loss = 3408678.25\n",
            "Loss = 3384401.75\n",
            "Loss = 3360330.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_img = np.array(image[0])"
      ],
      "metadata": {
        "id": "S-GPgg0dHUKW"
      },
      "execution_count": 273,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(cv.cvtColor(final_img, cv.COLOR_BGR2RGB))"
      ],
      "metadata": {
        "id": "GzDJusB2HUCn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_img = final_img * 255\n",
        "cv.imwrite('/content/final_image.png', final_img)"
      ],
      "metadata": {
        "id": "TmomEnOnFdKu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}